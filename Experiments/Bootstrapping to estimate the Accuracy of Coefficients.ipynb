{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bootstrapping to estimate the Accuracy of Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import *\n",
    "% matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the Data set\n",
    "df = pd.read_csv(\"Auto.csv\",na_values ='?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variable** | **__ Description__** |** Type**\n",
    "---|---|---\n",
    "mpg|Miles Per Gallon|Integer\n",
    "cylinders|Number of cylinders between 4 and 8|Integer\n",
    "displacement|Engine Displacement,Cu Inches|Integer\n",
    "horsepower|Horsepower|Integer\n",
    "weight|Vehicle weight(lbs)|Integer\n",
    "acceleration|Time to accelerate from 0 to 60 mph (Secs)|float\n",
    "year|Model year|Year of the Model\n",
    "origin|Origin of car (1. American, 2. European, 3. Japanese|qualitative\n",
    "name|Vehicle Name|String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 397 entries, 0 to 396\n",
      "Data columns (total 9 columns):\n",
      "mpg             397 non-null float64\n",
      "cylinders       397 non-null int64\n",
      "displacement    397 non-null float64\n",
      "horsepower      392 non-null float64\n",
      "weight          397 non-null int64\n",
      "acceleration    397 non-null float64\n",
      "year            397 non-null int64\n",
      "origin          397 non-null int64\n",
      "name            397 non-null object\n",
      "dtypes: float64(4), int64(4), object(1)\n",
      "memory usage: 28.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Checking for Null values\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach-\n",
    "- Calculate a simple linear regression with 1 predictor with statsmodel the caluclates the coefficient estimates along with the confidence interval\n",
    "- use Bootstrapping with sklearn and compare the estimates from 1 &2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_sm = smf.ols(formula='mpg~horsepower',data=df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.605</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   599.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 26 Sep 2016</td> <th>  Prob (F-statistic):</th> <td>7.03e-81</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>05:48:59</td>     <th>  Log-Likelihood:    </th> <td> -1178.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2361.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   390</td>      <th>  BIC:               </th> <td>   2369.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>   39.9359</td> <td>    0.717</td> <td>   55.660</td> <td> 0.000</td> <td>   38.525    41.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower</th> <td>   -0.1578</td> <td>    0.006</td> <td>  -24.489</td> <td> 0.000</td> <td>   -0.171    -0.145</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>16.432</td> <th>  Durbin-Watson:     </th> <td>   0.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  17.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.492</td> <th>  Prob(JB):          </th> <td>0.000175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.299</td> <th>  Cond. No.          </th> <td>    322.</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.606\n",
       "Model:                            OLS   Adj. R-squared:                  0.605\n",
       "Method:                 Least Squares   F-statistic:                     599.7\n",
       "Date:                Mon, 26 Sep 2016   Prob (F-statistic):           7.03e-81\n",
       "Time:                        05:48:59   Log-Likelihood:                -1178.7\n",
       "No. Observations:                 392   AIC:                             2361.\n",
       "Df Residuals:                     390   BIC:                             2369.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     39.9359      0.717     55.660      0.000        38.525    41.347\n",
       "horsepower    -0.1578      0.006    -24.489      0.000        -0.171    -0.145\n",
       "==============================================================================\n",
       "Omnibus:                       16.432   Durbin-Watson:                   0.920\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               17.305\n",
       "Skew:                           0.492   Prob(JB):                     0.000175\n",
       "Kurtosis:                       3.299   Cond. No.                         322.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value calculated for Beta_1 by SK learn is array([-0.15784473])-\n",
      "The value calculated for Beta_0 by SK learn is 39.935861021170467-\n"
     ]
    }
   ],
   "source": [
    "# Using Sklearn to calculate the coefficients on the full model\n",
    "X = df[['horsepower']]\n",
    "Y = df.mpg\n",
    "a = linear_model.LinearRegression(fit_intercept = True).fit(X,Y)\n",
    "print \"The value calculated for Beta_1 by SK learn is %r-\" %a.coef_\n",
    "print \"The value calculated for Beta_0 by SK learn is %r-\" %a.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The code below uses Bootstrapping techniques to get the values for std_dev that can be used tocalculate the Confidence intervals\n",
    "\n",
    "# empty lists ot hold the values of the coefficients\n",
    "beta_0 = []\n",
    "beta_1 = []\n",
    "# performing bootstrapping 1000 times\n",
    "for i in range(0,1000):\n",
    "    df_bootstrapped = df.sample(frac = 1, replace = True)\n",
    "    X = df_bootstrapped[['horsepower']]\n",
    "    Y = df_bootstrapped.mpg\n",
    "    temp_model = linear_model.LinearRegression().fit(X,Y)\n",
    "    beta_0.append(temp_model.intercept_) \n",
    "    beta_1.append(temp_model.coef_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The std err for Beta_0 is 0.84890978199449685\n",
      "The std err for Beta_1 is 0.0072787625688362223\n"
     ]
    }
   ],
   "source": [
    "print \"The std err for Beta_0 is %r\" %np.std(beta_0)\n",
    "print \"The std err for Beta_1 is %r\" %np.std(beta_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.238041457181474"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a.intercept_)-2*np.std(beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The 95 percent conf interval for intercept is  [38.238041457181474 , 41.63368058515946]\n",
      " The 95 percent conf interval for Coefficient is  [-0.172402 , -0.143287]\n"
     ]
    }
   ],
   "source": [
    "Beta_0_conf_lower_lim = (a.intercept_)-2*np.std(beta_0)\n",
    "Beta_0_conf_upper_lim = (a.intercept_)+2*np.std(beta_0)\n",
    "\n",
    "Beta_1_conf_lower_lim = (a.coef_)-2*np.std(beta_1)\n",
    "Beta_1_conf_upper_lim = (a.coef_)+2*np.std(beta_1)\n",
    "\n",
    "print \" The 95 percent conf interval for intercept is  [%r , %r]\" %(Beta_0_conf_lower_lim,Beta_0_conf_upper_lim)\n",
    "print \" The 95 percent conf interval for Coefficient is  [%f , %f]\" %(Beta_1_conf_lower_lim,Beta_1_conf_upper_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "- There seems to be a slight difference between the standard errors given by the OLS function and sklearn linear model\n",
    "- There is a general incliniation to lean towards the estimates given by bootstrapping due to the fokkowing reasons\n",
    "    - The OLS relies on certain assumptins(regd noise and its estimated Value) which skleanr does not\n",
    "    - OLS here would assume that the Xs are fixed which in reality are not\n",
    "    - With a bootstrapped approach you can generate new sample as and when needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
